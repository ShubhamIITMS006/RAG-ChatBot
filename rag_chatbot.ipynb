{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the PDF directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents():\n",
    "    document_loader = PyPDFDirectoryLoader(\"Data\")\n",
    "    return document_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS-R.2.1 Minimum Qualifications for Admission to the M.S programme100\n",
      "Candidates applying for the M.S programme in one of the following areas need to have any one of101\n",
      "the minimum qualifications mentioned in the table below.102\n",
      "Area Minimum Qualifications\n",
      "Educational Qualifications Additional Qualifications\n",
      "Engineering\n",
      "B.E/ B.Tech/ 4 year online / any recog-\n",
      "nised 4 year B.sc/ 4 year BS of IITs/\n",
      "CFTIs /UGC or Master’s degree in\n",
      "a relevant discipline, or equivalent.\n",
      "301st Senate Res. No 5/2023\n",
      "or\n",
      "Associate Membership of the follow-\n",
      "ing professional bodies of the discipline,\n",
      "provided they have passed parts A and B\n",
      "of the membership examinations: The\n",
      "Institution of Engineers (India)(Civil,\n",
      "Mechanical, Electrical and Electronics,\n",
      "Electronics and Communications), The\n",
      "Aeronautical Society of India, The In-\n",
      "dian Institute of Metals, The Indian In-\n",
      "stitute of Chemical Engineers, The In-\n",
      "stitute of Electronics & Telecommunica-\n",
      "tion Engineering and other professional\n",
      "bodies approved by the Senate from time\n",
      "to time.\n",
      "or\n",
      "4 year online or any recognized 4 year\n",
      "BSc / 4 Year BS of IITs/ CFTIs/ UGC\n",
      "305th Senate Res. No 51/2023\n",
      "For Computer Science and Engi-\n",
      "neering. BSc (Maths/Stats/CS)\n",
      "+MSc (Maths/Stats/CS) holders\n",
      "from any recognized Institute/ Uni-\n",
      "versity, provided they have a valid\n",
      "GATE score (in CS/MA), or UGC-\n",
      "NET/CSIRNET/ NBHM/Inspire or\n",
      "equivalent qualification tenable for the\n",
      "year of registration, are also eligible.\n",
      "299th Senate Res. No 57/2022\n",
      "Valid GATE score\n",
      "is required for\n",
      "Regular-HTRA,\n",
      "Regular-Fellowship\n",
      "and Regular-\n",
      "Project-HTRA\n",
      "categories, except\n",
      "4 yr B.S/4 yr\n",
      "B.Sc./B.E/B.Tech\n",
      "from a Centrally\n",
      "Funded Technical\n",
      "Institute (CFTI)\n",
      "with CGPA ≥ 8.\n",
      "301st Senate Res. No 5/2023\n",
      "Page 3 of 16\n"
     ]
    }
   ],
   "source": [
    "documents = load_documents()            ## list of tuples, where tuple contains page_content & meta_data\n",
    "print(documents[25].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the pages into smaller Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 1000,\n",
    "        chunk_overlap = 200,\n",
    "        length_function = len,              # Decides how the length of the chunk is calculated. len : character count; tiktoken: token based; lambda x : x.split(): word based\n",
    "        is_separator_regex=False            # By default, the splitter uses a list of preferred string separators, eg. [\"\\n\\n\", \"\\n\", \" \", \"\"]. When false the separaters are treated as a plain string but when true split is done based on complex splitting logic.\n",
    "    )\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "## Normal seperator & Regex(Regular Expression) separators\n",
    "## Normal separators are like saying: “Split the text wherever you see this exact substring. Example: split on \"--\" means you only cut when you see two hyphens next to each other.\n",
    "## Regex separators are like saying: “Split the text wherever a pattern matches,” which can describe many possibilities compactly. Example: split on \\s+ means “any run of whitespace (spaces, tabs, newlines)” — not a fixed string, but a pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='However, in the case of service officers under the control of Army / Navy / Airforce / DRDO, \n",
      "the selection will be through a central selection committee(s) with the Institute faculty serving \n",
      "on the selection committee. \n",
      " \n",
      "R.1.9 Vacancies, if required to be filled up after the admission date, will be decided by the \n",
      "Chairman, Senate, and reported to the Senate for post-facto approval. \n",
      " \n",
      "R.1.10 In all matters concerning the selection of candidates, the decision of the Chairman, Senate, or \n",
      "his / her nominee, viz. Chairman, M.Tech Admissions Committee, is final. \n",
      " \n",
      "R1.11 In addition to satisfying the conditions given in the information Brochure for M.Tech Admission \n",
      "sent along with the application forms, the selected candidates should satisfy the other \n",
      "admission requirements indicated in the offer letter of admission. Only then, they will be   \n",
      "3' metadata={'producer': 'convertonlinefree.com', 'creator': 'convertonlinefree.com', 'creationdate': '2016-04-11T11:36:51+00:00', 'moddate': '2016-04-11T17:08:52-07:00', 'source': 'Data\\\\m.tech-2015.pdf', 'total_pages': 19, 'page': 3, 'page_label': '4'}\n"
     ]
    }
   ],
   "source": [
    "documents = load_documents()\n",
    "chunks = split_documents(documents)             ## List of lists\n",
    "print(chunks[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Indexing of the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function is used to assign unique and tracable id to each chunk.\n",
    "\n",
    "def define_chunk_ids(chunks):\n",
    "    last_page_id = None\n",
    "    current_chunk_index = 0\n",
    "    for chunk in chunks:\n",
    "        source = chunk.metadata.get(\"source\")\n",
    "        page = chunk.metadata.get(\"page_label\")\n",
    "        current_page_id = f\"{source}:{page}\"\n",
    "\n",
    "        # Increment the chunk index for every chunk, regardless of the page\n",
    "        current_chunk_index += 1\n",
    "\n",
    "        chunk_id = f\"{current_page_id}:{current_chunk_index}\"\n",
    "        last_page_id = current_page_id\n",
    "        chunk.metadata[\"id\"] = chunk_id\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embedding Function (illustrative)\n",
    "\n",
    "#### To create the database and to extract data by querying the database.\n",
    "\n",
    "This is saved as a python function in .py file for reuse. Here, we use `OllamaEmbeddings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "def get_embedding_function():\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name = \"sentence-transformers/all-miniLM-L6-v2\",\n",
    "        # trust_remote_code=True\n",
    "    )\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (0.3.27)\n",
      "Requirement already satisfied: langchain-community in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (0.3.27)\n",
      "Requirement already satisfied: pypdf in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (5.9.0)\n",
      "Requirement already satisfied: chromadb in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (1.0.15)\n",
      "Requirement already satisfied: pytest in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (8.4.1)\n",
      "Requirement already satisfied: langchain-ollama in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from -r requirements.txt (line 6)) (0.3.6)\n",
      "Requirement already satisfied: langchain-chroma in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from -r requirements.txt (line 7)) (0.2.5)\n",
      "Requirement already satisfied: langchain-huggingface in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from -r requirements.txt (line 8)) (0.3.1)\n",
      "Requirement already satisfied: transformers in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from -r requirements.txt (line 9)) (4.54.1)\n",
      "Requirement already satisfied: huggingface-hub in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from -r requirements.txt (line 10)) (0.34.3)\n",
      "Requirement already satisfied: sentence-transformers in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from -r requirements.txt (line 11)) (5.0.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from langchain->-r requirements.txt (line 1)) (0.3.72)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from langchain->-r requirements.txt (line 1)) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from langchain->-r requirements.txt (line 1)) (0.4.10)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from langchain->-r requirements.txt (line 1)) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from langchain->-r requirements.txt (line 1)) (2.0.42)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from langchain->-r requirements.txt (line 1)) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from langchain->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->-r requirements.txt (line 1)) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->-r requirements.txt (line 1)) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->-r requirements.txt (line 1)) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->-r requirements.txt (line 1)) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 1)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 1)) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 1)) (3.2.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from langchain-community->-r requirements.txt (line 2)) (3.12.15)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from langchain-community->-r requirements.txt (line 2)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from langchain-community->-r requirements.txt (line 2)) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from langchain-community->-r requirements.txt (line 2)) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from langchain-community->-r requirements.txt (line 2)) (2.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 2)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 2)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 2)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 2)) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 2)) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 2)) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 2)) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->-r requirements.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: build>=1.0.3 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 4)) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 4)) (0.35.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 4)) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 4)) (1.22.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 4)) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 4)) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 4)) (1.36.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 4)) (0.21.4)\n",
      "Requirement already satisfied: pypika>=0.48.9 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 4)) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 4)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 4)) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 4)) (1.74.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 4)) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 4)) (0.16.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 4)) (33.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 4)) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 4)) (3.11.1)\n",
      "Requirement already satisfied: httpx>=0.27.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 4)) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 4)) (14.1.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 4)) (4.25.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requirements.txt (line 4)) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requirements.txt (line 4)) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requirements.txt (line 4)) (1.9.0)\n",
      "Requirement already satisfied: colorama>=0.4 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from pytest->-r requirements.txt (line 5)) (0.4.6)\n",
      "Requirement already satisfied: iniconfig>=1 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from pytest->-r requirements.txt (line 5)) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from pytest->-r requirements.txt (line 5)) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from pytest->-r requirements.txt (line 5)) (2.19.2)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.5.1 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from langchain-ollama->-r requirements.txt (line 6)) (0.5.1)\n",
      "Requirement already satisfied: filelock in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from transformers->-r requirements.txt (line 9)) (3.18.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from transformers->-r requirements.txt (line 9)) (2025.7.34)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from transformers->-r requirements.txt (line 9)) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from huggingface-hub->-r requirements.txt (line 10)) (2025.7.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 11)) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 11)) (1.7.1)\n",
      "Requirement already satisfied: scipy in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 11)) (1.16.1)\n",
      "Requirement already satisfied: Pillow in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 11)) (11.3.0)\n",
      "Requirement already satisfied: pyproject_hooks in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: anyio in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 4)) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb->-r requirements.txt (line 4)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb->-r requirements.txt (line 4)) (0.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 4)) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 4)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 4)) (0.26.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (3.3.1)\n",
      "Requirement already satisfied: durationpy>=0.7 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (0.10)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 4)) (0.6.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 1)) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 4)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 4)) (25.2.10)\n",
      "Requirement already satisfied: protobuf in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 4)) (6.31.1)\n",
      "Requirement already satisfied: sympy in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 4)) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 4)) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 4)) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 4)) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.36.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 4)) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb->-r requirements.txt (line 4)) (0.57b0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from rich>=10.11.0->chromadb->-r requirements.txt (line 4)) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb->-r requirements.txt (line 4)) (0.1.2)\n",
      "Requirement already satisfied: networkx in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 11)) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 11)) (3.1.6)\n",
      "Requirement already satisfied: setuptools in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 11)) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 4)) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 4)) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 4)) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 4)) (15.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 4)) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 4)) (3.5.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers->-r requirements.txt (line 11)) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 11)) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\machine learning\\projects\\project-6\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 11)) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the vector Database and Enabling Auto-addition of a new file\n",
    "\n",
    "When a new file is added to the \"data\" directory, the program will detect this based on the index and add them without complete updation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from get_embedding_function import get_embedding_function\n",
    "from langchain_chroma.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  This function helps in adding document chunks to the chroma vector database\n",
    "import shutil\n",
    "CHROMA_PATH = \"chroma_new\"                                     # the directory where the Chroma database is stored or will be created.\n",
    "def add_to_chromadb(chunks: list[Document]):\n",
    "    db = Chroma(\n",
    "        collection_name= \"chunks\", persist_directory=CHROMA_PATH, embedding_function=get_embedding_function()\n",
    "    )\n",
    "\n",
    "    chunks_with_ids = define_chunk_ids(chunks)\n",
    "\n",
    "    existing_chunks = db.get(include =[])                   # nothing in include means documents, metadata & embedding won't be loaded but only ids will be loaded in vector store               \n",
    "    existing_ids = set(existing_chunks[\"ids\"])              # list of ids are converted to set for fast lookups (not the chunk id but the id that is created by default)\n",
    "    print(f\"Number of existing documents in DB: {len(existing_ids)}\")\n",
    "\n",
    "    new_chunks = []\n",
    "    for chunk in chunks_with_ids:\n",
    "        if chunk.metadata[\"id\"] not in existing_ids:\n",
    "            new_chunks.append(chunk)                    ## list of chunks which will contain page_content & metadata\n",
    "        \n",
    "    if len(new_chunks):\n",
    "        print(f\"New {len(new_chunks)} documents added to the DB\")\n",
    "        new_chunk_ids = [chunk.metadata[\"id\"] for chunk in new_chunks]\n",
    "        shutil.rmtree('./chroma_db', ignore_errors=True)# List of chunk ids that  we have created\n",
    "        db.add_documents(new_chunks, ids = new_chunk_ids)\n",
    "        # db.persist()\n",
    "        print(\"chunk embedded!\")\n",
    "    else:\n",
    "        print(\"No documents to add!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Machine Learning\\Projects\\Project-6\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of existing documents in DB: 515\n",
      "No documents to add!\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--reset\", action=\"store_true\", help=\"Reset the database.\")\n",
    "args = parser.parse_known_args()\n",
    "# if args.reset:\n",
    "#     print(\"Clearing Database\")\n",
    "#     clear_database()\n",
    "add_to_chromadb(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "from get_embedding_function import get_embedding_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_PATH = \"chroma_new\"\n",
    "\n",
    "sys_instructions = SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"You are an academic assistant chatbot for a university. \n",
    "You specialize in answering questions about the Ordinances and Regulations related to M.Tech, MS, and PhD programs. \n",
    "\n",
    "Your job is to:\n",
    "- Provide **accurate**, **clear**, and **concise** responses using the information available in the university's official ordinance documents.\n",
    "- **Stick strictly to the content** in the provided documents. If the answer is not found, say: \"I'm sorry, that information isn't available in the current document.\"\n",
    "- Explain terms in simple, student-friendly language when necessary.\n",
    "- When questions are ambiguous, **ask for clarification** instead of guessing.\n",
    "- Always maintain a **formal and helpful** tone.\n",
    "\n",
    "The document includes topics like:\n",
    "- Course structure and credits\n",
    "- Registration and thesis submission rules\n",
    "- Evaluation procedures and grading\n",
    "- Leaves and attendance\n",
    "- Program duration and extension policies\n",
    "- Comprehensive exam and academic misconduct policies\n",
    "\n",
    "You are not allowed to provide speculative advice or answer beyond what is present in the document.\n",
    "Question: \n",
    "{question}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "rag_context = HumanMessagePromptTemplate.from_template(\"Answer the question based on the following context: {context} Question: {question}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='You are an academic assistant chatbot for a university. \\nYou specialize in answering questions about the Ordinances and Regulations related to M.Tech, MS, and PhD programs. \\n\\nYour job is to:\\n- Provide **accurate**, **clear**, and **concise** responses using the information available in the university\\'s official ordinance documents.\\n- **Stick strictly to the content** in the provided documents. If the answer is not found, say: \"I\\'m sorry, that information isn\\'t available in the current document.\"\\n- Explain terms in simple, student-friendly language when necessary.\\n- When questions are ambiguous, **ask for clarification** instead of guessing.\\n- Always maintain a **formal and helpful** tone.\\n\\nThe document includes topics like:\\n- Course structure and credits\\n- Registration and thesis submission rules\\n- Evaluation procedures and grading\\n- Leaves and attendance\\n- Program duration and extension policies\\n- Comprehensive exam and academic misconduct policies\\n\\nYou are not allowed to provide speculative advice or answer beyond what is present in the document.\\nQuestion: \\n{question}\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based on the following context: {context} Question: {question}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([sys_instructions, rag_context])\n",
    "print(chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = get_embedding_function()\n",
    "data_base = Chroma(collection_name=\"chunks\", persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "\n",
    "def query_rag(query_text: str):\n",
    "    # Prepare the DB.\n",
    "    embedding_function = get_embedding_function()\n",
    "    db = data_base\n",
    "\n",
    "    # Search the DB.\n",
    "    results = db.similarity_search_with_score(query_text, k=5)\n",
    "    # print(results)\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "    # prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "    # prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "    prompt = chat_prompt.format(context=context_text, question=query_text)\n",
    "    # print(prompt)\n",
    "\n",
    "    # Use OllamaLLM for generating the response text\n",
    "    model = OllamaLLM(model=\"mistral\")\n",
    "    # model = OllamaLLM(model=\"gemma3:1b\")\n",
    "\n",
    "    response_text = model.invoke(prompt)\n",
    "\n",
    "    sources = [doc.metadata.get(\"id\", None) for doc, _score in results]\n",
    "    formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "    # formatted_response = f\"Response: {response_text}\"\n",
    "    # print(formatted_response)\n",
    "    return formatted_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is leave policy for PhDs\n"
     ]
    }
   ],
   "source": [
    "# generated with mistral\n",
    "query_text= input(\"User: \")\n",
    "print(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Machine Learning\\Projects\\Project-6\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:  Response:  Based on the provided document, the leave policy for PhD students at your university is as follows:\n",
      "\n",
      "1. PhD students should apply to the Head of the Department for leave stating the reasons whenever they are not able to attend classes or project work. (R.15.1)\n",
      "2. PhD students are eligible for 8 days of casual leave and 15 days of vacation leave per academic year. (R.15.2)\n",
      "3. The unutilized leave from the first year cannot be carried over to the second year. (Not specified in a rule number but implied from the statement about long leave not being availed in the month of June following the second semester, as project work has to commence on that date.)\n",
      "4. Medical leaves can be considered by the Dean(AR) to extend the registration period of the program for up to a maximum period of one year, provided it is duly certified by the Institute Hospital. (R.15.0)\n",
      "Sources: ['Data\\\\m.tech-2015.pdf:12:40', 'Data\\\\PhD_Ordinance_updated-01-04-2024.pdf:12:260', 'Data\\\\m.tech-2015.pdf:12:61', 'Data\\\\MS_Ordinances_20_03_2024.pdf:14:179', 'Data\\\\PhD_Ordinance_updated-01-04-2024.pdf:12:167']\n"
     ]
    }
   ],
   "source": [
    "# generated with mistral\n",
    "response= query_rag(query_text)\n",
    "print(\"Response: \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the admission criteria for Phd and Mtech\n"
     ]
    }
   ],
   "source": [
    "# generated with mistral\n",
    "query_text= input(\"User: \")\n",
    "print(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Machine Learning\\Projects\\Project-6\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:  Based on the provided document, here are the admission criteria for both PhD and M.Tech programs:\n",
      "\n",
      "For **PhD** Program:\n",
      "There are three modes of admission: Regular Ph.D, Direct Admission to the M.S+Ph.D Programme, and Upgraded Ph.D.\n",
      "\n",
      "1. **Regular Ph.D**: Candidates applying for this program in engineering need to have any one of the following minimum qualifications:\n",
      "   - M.E/M.Tech/M.S by Research in Engineering/5-year integrated Masters/Dual Degree in engineering.\n",
      "   - 2 year M.Sc from IITs (entry through JAM) with a CGPA of ≥ 8.\n",
      "   - B.S+M.S (5-year integrated) from CFTI with a CGPA of ≥ 8.\n",
      "\n",
      "2. **Direct Admission to the M.S+Ph.D Programme**: The minimum qualifications for this mode are not specified in the document provided, but it is mentioned that they should be in relevant areas/disciplines as provided by the respective departments.\n",
      "\n",
      "3. **Upgraded Ph.D**: Candidates registered for M.S/MTech/MSc at IITM are eligible for upgradation to the Ph.D program if they satisfy certain criteria, such as completing a specific number of courses with a certain GPA within a specified period.\n",
      "\n",
      "For **M.Tech** Program:\n",
      "The document provided does not specify the admission criteria for the M.Tech program explicitly. However, it is mentioned that candidates applying for the Ph.D program in engineering need to have an M.Tech degree as one of the minimum qualifications. So, it can be inferred that the admission criteria for M.Tech might be similar or related to the ones mentioned for the PhD program in engineering.\n",
      "\n",
      "Please refer to the respective department brochures for detailed information about the admission criteria for each discipline. If you have any more specific questions regarding these programs, feel free to ask!\n",
      "Sources: ['Data\\\\PhD_Ordinance_updated-01-04-2024.pdf:2:193', 'Data\\\\PhD_Ordinance_updated-01-04-2024.pdf:2:124', 'Data\\\\PhD_Ordinance_updated-01-04-2024.pdf:3:216', 'Data\\\\PhD_Ordinance_updated-01-04-2024.pdf:3:140', 'Data\\\\PhD_Ordinance_updated-01-04-2024.pdf:8:153']\n"
     ]
    }
   ],
   "source": [
    "# generated with mistral\n",
    "response = query_rag(query_text)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admission Criteria for Btech\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Machine Learning\\Projects\\Project-6\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:  Based on the provided document, the information about admission criteria for a Bachelor of Technology (B.Tech) program is not explicitly stated. However, the document does provide information related to the admission criteria for the M.S+Ph.D program, which includes external candidates with a proven research record and top 10% students from other institutions that have a specific MoU with IITM. These students can apply for direct admission to the M.S+Ph.D program in their 4th year, and the credits earned during the first year of this program will have equivalence to the 4th year of the B.Tech in their parent institution. The scholars are eligible for HTRA (Higher Research Assistance) for 5 years after completing their first year successfully at IITM and qualifying in GATE or without GATE for students from CFTIs with a CGPA ≥ 8 on a 10.0 point scale.\n",
      "\n",
      "For further clarification, it would be best to consult the official ordinance document regarding the B.Tech admission criteria or contact the admissions office at IITM directly.\n",
      "Sources: ['Data\\\\PhD_Ordinance_updated-01-04-2024.pdf:8:235', 'Data\\\\PhD_Ordinance_updated-01-04-2024.pdf:8:151', 'Data\\\\PhD_Ordinance_updated-01-04-2024.pdf:8:237', 'Data\\\\PhD_Ordinance_updated-01-04-2024.pdf:8:152', 'Data\\\\PhD_Ordinance_updated-01-04-2024.pdf:8:236']\n"
     ]
    }
   ],
   "source": [
    "# generated with mistral\n",
    "query_text= input(\"User: \")\n",
    "print(query_text)\n",
    "response = query_rag(query_text)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How long is the PhD degree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Machine Learning\\Projects\\Project-6\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:  Based on the information provided in the document, the minimum duration for a regular Ph.D program is 2 years and the maximum duration is 5 years from the date of registration to the date of submission of the thesis for full-time research scholars. However, the Dean's Committee (DC) may grant an extension of up to 2 more years to submit the thesis. Additionally, an additional year may be allowed for scholars in certain categories such as QIP, external, part-time, and staff. It is important to note that this timeline is indicative and specific time frames for different categories can be found in the respective sections of the document.\n",
      "Sources: ['Data\\\\PhD_Ordinance_updated-01-04-2024.pdf:19:295', 'Data\\\\PhD_Ordinance_updated-01-04-2024.pdf:19:190', 'Data\\\\PhD_Ordinance_updated-01-04-2024.pdf:2:193', 'Data\\\\PhD_Ordinance_updated-01-04-2024.pdf:9:245', 'Data\\\\PhD_Ordinance_updated-01-04-2024.pdf:13:168']\n"
     ]
    }
   ],
   "source": [
    "query_text= input(\"User: \")\n",
    "print(query_text)\n",
    "response = query_rag(query_text)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "# import difflib\n",
    "\n",
    "# def normalize(text):\n",
    "#     # Lowercase, strip punctuation, and collapse whitespace\n",
    "#     text = text.lower().strip()\n",
    "#     text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "#     return ' '.join(text.split())\n",
    "\n",
    "# def evaluate_retrieval_metrics(retriever, queries, ground_truths, k=5):\n",
    "#     \"\"\"Calculate Recall@k and MRR for a set of queries.\"\"\"\n",
    "#     assert len(queries) == len(ground_truths), \"Mismatch in query and ground truth counts\"\n",
    "\n",
    "#     recall_total = 0\n",
    "#     reciprocal_ranks = []\n",
    "\n",
    "#     for query, truth in zip(queries, ground_truths):\n",
    "#         results = retriever.similarity_search_with_score(query, k=k)\n",
    "#         retrieved_texts = [doc.page_content for doc, score in results]\n",
    "\n",
    "#         normalized_truth = normalize(truth)\n",
    "#         found = False\n",
    "\n",
    "#         for rank, text in enumerate(retrieved_texts, 1):\n",
    "#             if normalized_truth in normalize(text):\n",
    "#                 recall_total += 1\n",
    "#                 reciprocal_ranks.append(1 / rank)\n",
    "#                 found = True\n",
    "#                 break\n",
    "\n",
    "#         if not found:\n",
    "#             reciprocal_ranks.append(0)\n",
    "\n",
    "#     recall_at_k = recall_total / len(queries)\n",
    "#     mrr = sum(reciprocal_ranks) / len(queries)\n",
    "\n",
    "#     print(f\"Recall@{k}: {recall_at_k:.4f}\")\n",
    "#     print(f\"MRR: {mrr:.4f}\")\n",
    "\n",
    "# def evaluate_retrieval_metrics(retriever, queries, ground_truths, k=5, threshold=0.5):\n",
    "#     assert len(queries) == len(ground_truths), \"Mismatch in query and ground truth counts\"\n",
    "\n",
    "#     recall_total = 0\n",
    "#     reciprocal_ranks = []\n",
    "\n",
    "#     for query, truth in zip(queries, ground_truths):\n",
    "#         results = retriever.similarity_search_with_score(query, k=k)\n",
    "#         normalized_truth = normalize(truth)\n",
    "\n",
    "#         found = False\n",
    "\n",
    "#         for rank, (doc, score) in enumerate(results, 1):\n",
    "#             retrieved_text = normalize(doc.page_content)\n",
    "#             similarity = difflib.SequenceMatcher(None, normalized_truth, retrieved_text).ratio()\n",
    "\n",
    "#             if similarity > threshold:\n",
    "#                 recall_total += 1\n",
    "#                 reciprocal_ranks.append(1 / rank)\n",
    "#                 found = True\n",
    "#                 break\n",
    "\n",
    "#         if not found:\n",
    "#             reciprocal_ranks.append(0)\n",
    "\n",
    "#     recall_at_k = recall_total / len(queries)\n",
    "#     mrr = sum(reciprocal_ranks) / len(queries)\n",
    "\n",
    "#     print(f\"Recall@{k}: {recall_at_k:.4f}\")\n",
    "#     print(f\"MRR: {mrr:.4f}\")\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm  # for progress bar\n",
    "\n",
    "# Load sentence embedding model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # small and fast\n",
    "\n",
    "def semantic_similarity(text1, text2):\n",
    "    \"\"\"Compute cosine similarity between two texts using embeddings.\"\"\"\n",
    "    emb1 = embedding_model.encode(text1, convert_to_tensor=True)\n",
    "    emb2 = embedding_model.encode(text2, convert_to_tensor=True)\n",
    "    return util.pytorch_cos_sim(emb1, emb2).item()  # returns a float\n",
    "\n",
    "def evaluate_mme(retriever, queries, ground_truths, k=5, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate retrieval using semantic similarity.\n",
    "    Computes Recall@k and MRR.\n",
    "    \"\"\"\n",
    "    assert len(queries) == len(ground_truths), \"Mismatch in query and ground truth lengths\"\n",
    "\n",
    "    recall_total = 0\n",
    "    reciprocal_ranks = []\n",
    "\n",
    "    for query, ground_truth in tqdm(zip(queries, ground_truths), total=len(queries), desc=\"Evaluating\"):\n",
    "        results = retriever.similarity_search_with_score(query, k=k)\n",
    "\n",
    "        found = False\n",
    "\n",
    "        for rank, (doc, _) in enumerate(results, 1):\n",
    "            similarity = semantic_similarity(ground_truth, doc.page_content)\n",
    "\n",
    "            if similarity >= threshold:\n",
    "                recall_total += 1\n",
    "                reciprocal_ranks.append(1 / rank)\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        if not found:\n",
    "            reciprocal_ranks.append(0)\n",
    "\n",
    "    recall_at_k = recall_total / len(queries)\n",
    "    mrr = sum(reciprocal_ranks) / len(queries)\n",
    "\n",
    "    print(f\"\\nMME Evaluation:\")\n",
    "    print(f\"Recall@{k}: {recall_at_k:.4f}\")\n",
    "    print(f\"MRR: {mrr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MME Evaluation:\n",
      "Recall@5: 0.7500\n",
      "MRR: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"What is the upgradation criteria from Mtech to PhD\",\n",
    "    \"What is the criteria for admission in MS\",\n",
    "    \"how many days of leave can PhD take in a year\",\n",
    "    \"What is the attendance criteria to sit in the exam for Mtech students\"\n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "    \"completed four courses during the first semester and obtained a CGPA ≥ 8.1\",\n",
    "    \"should possess a B.E/B.Tech degree or its equivalent from a recognized institute\",\n",
    "    \"Based on the provided document, PhD students are eligible for 8 days of casual leave and 15 days of vacation leave per academic year\",\n",
    "    \"Based on the provided document, M.Tech students who have less than 85% attendance in a course are not permitted to sit for the end-semester exam without the permission of the Dean Academic Courses. This criterion is specified in R.14.3. It's important to note that this rule applies only to end-semester examinations, and students who have missed sessional assessments for valid reasons can apply for a makeup examination (R.20.1). If you have any further questions or need clarification on specific terms, feel free to ask\"\n",
    "]\n",
    "\n",
    "evaluate_mme(retriever=data_base, queries=queries, ground_truths=ground_truths, k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shubham\\AppData\\Local\\Temp\\ipykernel_19540\\1934874141.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot with memory ready! Type 'exit' to quit.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Machine Learning\\Projects\\Project-6\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User what are the duty that a PhD student perform for the stipend\n",
      "Bot:  Based on the provided context, it is not explicitly stated what specific duties a Ph.D. student must perform to receive their stipend. However, some general responsibilities can be inferred from the regulations. For instance, the student is required to enroll every semester (PhD-R.9 Enrollment), observe disciplined and decorous behavior (PhD-R.23 Discipline), and follow the regulations as outlined in the rules (PhD-R.24 Power to Modify). Additionally, Ph.D. candidates employed in government R&D organizations, public-sector undertakings, or DST(DSIR) approved organizations with at least 2 years of relevant experience are required to submit a \"No Objection Certificate\" and a commitment letter from their parent organization (PhD-R.7.284). These requirements suggest that the student should be actively engaged in their research and adhere to certain standards of conduct and employment status to maintain their stipend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Machine Learning\\Projects\\Project-6\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User stop\n",
      "Bot:  Based on the provided context, there isn't a specific rule given regarding when a PhD student would cease receiving their stipend. However, the registration of a research scholar whose progress is not found to be satisfactory by the DC (PhD-R.19) or who has not submitted his/her thesis before the end of the maximum permissible period (PhD-R.16) will be canceled, which might imply that the stipend could be affected due to these reasons. But without explicit information about the stipend and its associated rules, it's hard to provide a definitive answer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Machine Learning\\Projects\\Project-6\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User stop\n",
      "Bot:  Based on the provided context, there is no explicit information about the conditions under which a PhD student's stipend might be terminated. The text focuses more on the rules related to registration cancellation and temporary withdrawal from the program. However, it is important to note that the cancellation of registration could potentially imply the termination of the stipend, as registration seems to be a prerequisite for receiving financial support. But without explicit information about the stipend and its terms, this answer can only be speculative.\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# Create a windowed memory (last 5 turns)\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    k=5,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "# Create a conversational RAG chain\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=OllamaLLM(model=\"mistral\"),\n",
    "    retriever=data_base.as_retriever(),\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"Chatbot with memory ready! Type 'exit' to quit.\\n\")\n",
    "while True:\n",
    "    query = input(\"You: \")\n",
    "    if query.lower() in [\"exit\", \"quit\", \"stop\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    response = qa_chain.invoke({\"question\": query})\n",
    "    print(\"User\", query)\n",
    "    print(\"Bot:\", response['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
